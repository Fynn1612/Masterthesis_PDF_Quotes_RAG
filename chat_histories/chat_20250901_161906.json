[
  {
    "question": "What is epistemic uncertainty",
    "answer": "Epistemic uncertainty refers to the lack of knowledge about the process or the finite amount of training data (**uncertainty_slides.pdf**, page 32; **uncertainty_slides.pdf**, page 30; **dietterich-uncertainty-quantification-in-machine-learning-final.pdf**, page 11). It is also known as systematic uncertainty (**Aleatoric and Epistemic Uncertainty in RF.pdf**, page 0).\n\nKey characteristics of epistemic uncertainty:\n*   It detects samples far from the training distribution (**uncertainty_slides.pdf**, page 32; **uncertainty_slides.pdf**, page 33). A model should be more uncertain about its prediction in regions where it was not trained, which can be used to classify inputs as out-of-distribution (**DEEPLY UNCERTAIN COMPARING METHODS OF UNCERTAINTY QUANTIFICATION IN DEEP LEARNING ALGORITHMS.pdf**, page 5; **Deeply uncertain comparing methods of uncertainty quantification in deep learning algorihms.pdf**, page 6).\n*   It disappears or drops given enough data (**uncertainty_slides.pdf**, page 32; **uncertainty_slides.pdf**, page 33; **dietterich-uncertainty-quantification-in-machine-learning-final.pdf**, page 11). As such, it is the reducible part of the total uncertainty (**Aleatoric and Epistemic Uncertainty in RF.pdf**, page 0).\n*   It is associated with the model itself, and the uncertainty quantification method interacts directly with the model (**A Deeper Look into Aleatoric and Epistemic Uncertainty Disentanglement.pdf**, page 5).\n*   High epistemic uncertainty implies that the model's knowledge is limited (**Masterarbeit Detecting_Uncertainty.pdf**, page 24).\n*   Modeling epistemic variance is more beneficial when training data is small (**uncertainty_slides.pdf**, page 112).\n*   It can be detected by training many models and observing where they disagree (**uncertainty_slides.pdf**, page 33).\n*   In a non-stationary world, there is always epistemic uncertainty because enough data is never observed to converge (**dietterich-uncertainty-quantification-in-machine-learning-final.pdf**, page 11).\n*   Epistemic uncertainty will be high if class probabilities strongly vary within the set of plausible hypotheses, meaning there is uncertainty on how to compare these probabilities (**Aleatoric and Epistemic Uncertainty in RF.pdf**, page 4).\n\nThe concepts of aleatoric and epistemic uncertainty are unambiguous when defined within the framework of a model. What is considered aleatoric in one model may be epistemic in another, and depending on design decisions, aleatoric uncertainty can turn into epistemic uncertainty and vice versa (**A Structured Review of Literature on Uncertainty in Machine.pdf**, page 6). Both types of uncertainty play an important role in Machine Learning, where the learner's state of knowledge depends on the amount of data seen so far (**Representation of Quantification of Uncertainty in ML.pdf**, page 11). Epistemic uncertainty is also closely tied to \"model uncertainty\" or \"approximation uncertainty\" (**A Structured Review of Literature on Uncertainty in Machine.pdf**, page 15; **Aleatoric and Epistemic Uncertainty in Machine Learning An Introduction to Concepts and Methods.pdf**, page 6)."
  }
]